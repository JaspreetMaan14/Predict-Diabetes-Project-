{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkpj+Q82dz12Xl+0BPAWtr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaspreetMaan14/Predict-Diabetes-Project-/blob/main/Predict_Diabetes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Import the Necessary Libraries and the Data**\n"
      ],
      "metadata": {
        "id": "OJbciiW8EpPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhJZ7ZomEQN-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "diabetes = pd.read_csv('diabetes.csv')\n",
        "print(diabetes.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Print First 5 Rows\n",
        "diabetes.head()"
      ],
      "metadata": {
        "id": "O3kafNnPFJHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#No. of Rows and Columns\n",
        "print(\"dimension of diabetes data: {}\".format(diabetes.shape))"
      ],
      "metadata": {
        "id": "WdaIDYLwFTOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# No. of Diabitic and Non-Diabitic Persons\n",
        "# 1 --> Diabetes  and  0 --> No Diabetes\n",
        "print(diabetes.groupby('Outcome').size())"
      ],
      "metadata": {
        "id": "pfiQw0iaFeU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "import seaborn as sns\n",
        "sns.countplot(diabetes['Outcome'],label=\"Count\")"
      ],
      "metadata": {
        "id": "RFCTGeJ2F_tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Information\n",
        "diabetes.info()"
      ],
      "metadata": {
        "id": "uh7piX3aGIAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**K-Nearest Neighbors to Predict Diabetes**"
      ],
      "metadata": {
        "id": "dmPFVAIgGnvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The k-Nearest Neighbors algorithm is arguably the simplest machine learning algorithm. Building the model consists only of storing the training data set. To make a prediction for a new point in the dataset, the algorithm finds the closest data points in the training data set — its “nearest neighbors.”\n",
        "\n",
        "First, Let’s investigate whether we can confirm the connection between model complexity and accuracy:"
      ],
      "metadata": {
        "id": "mWEqvCTNGwtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(diabetes.loc[:, diabetes.columns != 'Outcome'], diabetes['Outcome'], stratify=diabetes['Outcome'], random_state=66)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "training_accuracy = []\n",
        "test_accuracy = []\n",
        "# try n_neighbors from 1 to 10\n",
        "neighbors_settings = range(1, 11)\n",
        "for n_neighbors in neighbors_settings:\n",
        "    # build the model\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "    knn.fit(X_train, y_train)\n",
        "    # record training set accuracy\n",
        "    training_accuracy.append(knn.score(X_train, y_train))\n",
        "    # record test set accuracy\n",
        "    test_accuracy.append(knn.score(X_test, y_test))\n",
        "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
        "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"n_neighbors\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QLx-FMpTGavN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=9)\n",
        "knn.fit(X_train, y_train)\n",
        "print('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))\n",
        "print('Accuracy of K-NN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "0MumGxz8HCon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "IIv7aokTHHsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "vF3cysSVHSJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy on the training set with Decision Tree Classifier is 100%, while the test set accuracy is much worse. This is an indicative that the tree is overfitting and not generalizing well to new data. Therefore, we need to apply pre-pruning to the tree."
      ],
      "metadata": {
        "id": "J3gmpjS2HV5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "Jzdt97kGHblP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Importance in Decision Trees\n",
        "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
      ],
      "metadata": {
        "id": "Dy_rar8vHfj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualization of the feature importance of decision tree to predict diabetes.\n",
        "def plot_feature_importances_diabetes(model):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    n_features = 8\n",
        "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
        "    plt.yticks(np.arange(n_features), diabetes_features)\n",
        "    plt.xlabel(\"Feature importance\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.ylim(-1, n_features)\n",
        "plot_feature_importances_diabetes(tree)"
      ],
      "metadata": {
        "id": "6FHL-3rQHosO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Deep Learning to Predict Diabetes**\n"
      ],
      "metadata": {
        "id": "x-KnV56iIKck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "print(\"Accuracy on training set: {:.2f}\".format(mlp.score(X_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.2f}\".format(mlp.score(X_test, y_test)))"
      ],
      "metadata": {
        "id": "IbIYCNvjII5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of the Multilayer perceptrons (MLP) is not as good as the other models at all, this is likely due to scaling of the data.|So,Now I will re-scale our data so that it fulfills these requirements to predict diabetes with a good accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "6jjftuBbIjoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n",
        "mlp = MLPClassifier(random_state=0)\n",
        "mlp.fit(X_train_scaled, y_train)\n",
        "print(\"Accuracy on training set: {:.3f}\".format(\n",
        "    mlp.score(X_train_scaled, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"
      ],
      "metadata": {
        "id": "9T_GN4QSH5yP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Heatmap of the first layer weights in a neural network learned on the to predict diabetes using the data set\n",
        "plt.figure(figsize=(20, 5))\n",
        "plt.imshow(mlp.coefs_[0], interpolation='none', cmap='viridis')\n",
        "diabetes_features = diabetes.columns[:-1] # Define diabetes_features\n",
        "plt.yticks(range(8), diabetes_features)\n",
        "plt.xlabel(\"Columns in weight matrix\")\n",
        "plt.ylabel(\"Input feature\")\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "id": "vVCnA9KBIyr2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}